import streamlit as st
import os
from PIL import Image
from ultralytics import YOLO
import numpy as np
import cv2
import torch
import time
import pandas as pd

# å¸¸é‡å®šä¹‰
FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX
FONT_SCALE = 0.8
FONT_THICKNESS = 2
BOX_THICKNESS = 2
BOX_COLOR = (0, 0, 255)
FONT_COLOR = (255, 255, 255)
DEFAULT_CONF = 0.25
DEFAULT_IOU = 0.7
DEFAULT_AUGMENT = False
DEFAULT_DEVICE = "CPU"


def yoloDetect(uploaded_file, conf, iou, augment, device):
    """ç›®æ ‡æ£€æµ‹å¹¶è¿”å›æ ‡æ³¨å›¾åƒå’Œæ£€æµ‹æ•°æ®"""
    with st.spinner("æ£€æµ‹ä¸­ï¼Œè¯·ç¨å€™..."):
        try:
            start_time = time.time()

            # å›¾åƒé¢„å¤„ç†
            img = Image.open(uploaded_file)
            img_array = np.array(img)
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

            # åŠ è½½æ¨¡å‹
            model = YOLO("./model/best.pt")

            # æ‰§è¡Œæ¨ç†
            results = model(
                img_array,
                conf=conf,
                iou=iou,
                augment=augment,
                device=device,
                verbose=False
            )
            result = results[0]

            detection_data = []
            wave_counter = 1

            # å¤„ç†æ¯ä¸ªæ£€æµ‹æ¡†
            for box in result.boxes:
                # åæ ‡è§£æ
                x1, y1, x2, y2 = map(int, box.xyxy[0])

                # ç‰¹å¾è®¡ç®—
                center_x = (x1 + x2) // 2
                center_y = (y1 + y2) // 2
                width = x2 - x1
                height = y2 - y1

                # è·å–æ£€æµ‹ä¿¡æ¯
                class_id = int(box.cls[0])
                confidence = float(box.conf[0])
                class_name = model.names[class_id]

                # æ”¶é›†æ•°æ®
                detection_data.append({
                    "id": wave_counter,
                    "name": class_name,
                    "ä¸­å¿ƒX": center_x,
                    "ä¸­å¿ƒY": center_y,
                    "é•¿": width,
                    "å®½": height,
                    "ç½®ä¿¡åº¦": confidence
                })

                # å¯è§†åŒ–æ ‡æ³¨
                label = f"{class_name}{wave_counter}"
                (label_width, label_height), _ = cv2.getTextSize(
                    label, FONT_FACE, FONT_SCALE, FONT_THICKNESS
                )

                # åŠ¨æ€æ ‡ç­¾ä½ç½®
                label_y = y1 - 10 if y1 - 10 > 10 else y1 + 20

                # ç»˜åˆ¶æ£€æµ‹æ¡†
                cv2.rectangle(
                    img_array,
                    (x1, y1),
                    (x2, y2),
                    BOX_COLOR,
                    BOX_THICKNESS
                )

                # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                cv2.rectangle(
                    img_array,
                    (x1, label_y - label_height),
                    (x1 + label_width, label_y),
                    BOX_COLOR,
                    cv2.FILLED,
                )

                # æ·»åŠ æ–‡æœ¬
                cv2.putText(
                    img_array,
                    label,
                    (x1, label_y),
                    FONT_FACE,
                    FONT_SCALE,
                    FONT_COLOR,
                    FONT_THICKNESS,
                )

                wave_counter += 1

            # è½¬æ¢é¢œè‰²ç©ºé—´
            output_img = Image.fromarray(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))

            # æ€§èƒ½ç»Ÿè®¡
            process_time = time.time() - start_time
            st.toast(f"æ£€æµ‹å®Œæˆï¼è€—æ—¶ {process_time:.2f}ç§’", icon="âœ…")

            return output_img, detection_data

        except Exception as e:
            st.error(f"æ£€æµ‹å¤±è´¥: {str(e)}")
            return None, []


def get_available_devices():
    """è·å–å¯ç”¨è®¡ç®—è®¾å¤‡åˆ—è¡¨"""
    devices = []
    if torch.cuda.is_available():
        devices.extend(f"cuda:{i}" for i in range(torch.cuda.device_count()))
    devices.append("cpu")
    return devices



def playground():
    """
    ä¿¡å·æ³¢å½¢æ£€æµ‹ä¸»ç•Œé¢ï¼ˆå®Œæ•´å¯è¿è¡Œç‰ˆæœ¬ï¼‰
    """
    # åˆå§‹åŒ–sessionçŠ¶æ€
    defaults = {
        "original_img": None,
        "conf": DEFAULT_CONF,
        "iou": DEFAULT_IOU,
        "augment": DEFAULT_AUGMENT,
        "devices": get_available_devices(),
        "device": get_available_devices()[0],
        "detection_data": None
    }
    for key, val in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = val

    # é¡µé¢æ ‡é¢˜å’Œåˆ†éš”çº¿
    st.header("CFES Signal Wave Detection System ğŸš€", divider="rainbow")

    # ========== ä¾§è¾¹æ è®¾ç½® ==========
    with st.sidebar:
        st.header("âš™ï¸ å‚æ•°è®¾ç½®", divider="blue")

        # ç½®ä¿¡åº¦å’ŒIOUè®¾ç½®
        st.session_state.conf = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, DEFAULT_CONF, 0.01,
            help="è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹ç»“æœçš„é˜ˆå€¼"
        )
        st.session_state.iou = st.slider(
            "IoUé˜ˆå€¼", 0.0, 1.0, DEFAULT_IOU, 0.01,
            help="éæå¤§å€¼æŠ‘åˆ¶çš„äº¤å¹¶æ¯”é˜ˆå€¼"
        )

        # é«˜çº§è®¾ç½®æŠ˜å åŒºåŸŸ
        with st.expander("é«˜çº§è®¾ç½®", expanded=False):
            st.session_state.augment = st.checkbox(
                "TTAå¢å¼º", DEFAULT_AUGMENT,
                help="å¯ç”¨æµ‹è¯•æ—¶æ•°æ®å¢å¼ºï¼ˆå¯èƒ½æé«˜ç²¾åº¦ä½†é™ä½é€Ÿåº¦ï¼‰"
            )

            # è®¾å¤‡é€‰æ‹©ç»„ä»¶
            device_info = []
            for dev in st.session_state.devices:
                if dev.startswith("cuda"):
                    idx = int(dev.split(":")[1])
                    prop = torch.cuda.get_device_properties(idx)
                    info = f"{prop.name} | æ˜¾å­˜ï¼š{prop.total_memory / 1024 ** 3:.1f}GB"
                else:
                    info = "CPU"
                device_info.append(info)

            st.session_state.device = st.selectbox(
                "è®¡ç®—è®¾å¤‡",
                options=st.session_state.devices,
                format_func=lambda x: device_info[st.session_state.devices.index(x)],
                index=0
            )

            # æ˜¾å­˜ç›‘æ§
            if st.session_state.device.startswith("cuda"):
                device_id = int(st.session_state.device.split(":")[1])
                mem_alloc = torch.cuda.memory_allocated(device_id) / 1024 ** 3
                mem_total = torch.cuda.get_device_properties(device_id).total_memory / 1024 ** 3
                st.metric("æ˜¾å­˜ä½¿ç”¨", f"{mem_alloc:.2f}/{mem_total:.2f} GB")

        # æ“ä½œæŒ‰é’®
        st.divider()
        detect_clicked = st.button("ğŸ” å¼€å§‹æ£€æµ‹", use_container_width=True)

    # ========== ä¸»ç•Œé¢å†…å®¹ ==========
    # æ ·æœ¬å›¾ç‰‡å±•ç¤ºåŒº
    with st.container(border=True):
        cols = st.columns(3)
        sample_images = {
            "img1": "img/img1.png",
            "img2": "img/img2.png",
            "img3": "img/img3.png"
        }
        for col, (name, path) in zip(cols, sample_images.items()):
            with col:
                st.image(path, caption=name, use_column_width=True)

    # å›¾ç‰‡é€‰æ‹©/ä¸Šä¼ åŒº
    selected_img = st.radio(
        "é€‰æ‹©è¾“å…¥æ¥æºï¼š",
        ["æ ·æœ¬å›¾ç‰‡", "ä¸Šä¼ å›¾ç‰‡"],
        horizontal=True,
        index=0
    )

    if selected_img == "ä¸Šä¼ å›¾ç‰‡":
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ£€æµ‹å›¾ç‰‡",
            type=["png", "jpg", "jpeg", "bmp", "tiff"],
            key="uploader"
        )
        if uploaded_file:
            st.session_state.original_img = uploaded_file
    else:
        img_choice = st.selectbox("é€‰æ‹©æ ·æœ¬å›¾ç‰‡", list(sample_images.keys()))
        st.session_state.original_img = sample_images[img_choice]

    # æ˜¾ç¤ºåŸå§‹å›¾ç‰‡
    if st.session_state.original_img:
        if isinstance(st.session_state.original_img, str):  # æ ·æœ¬å›¾ç‰‡è·¯å¾„
            img = Image.open(st.session_state.original_img)
        else:  # ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
            img = Image.open(st.session_state.original_img)

        with st.expander("åŸå§‹å›¾ç‰‡é¢„è§ˆ", expanded=True):
            st.image(img, caption="åŸå§‹å›¾ç‰‡", use_column_width=True)

    # æ‰§è¡Œæ£€æµ‹å¹¶æ˜¾ç¤ºç»“æœ
    if detect_clicked:
        if not st.session_state.original_img:
            st.warning("è¯·å…ˆé€‰æ‹©æˆ–ä¸Šä¼ å›¾ç‰‡ï¼")
            st.stop()

        try:
            # æ‰§è¡Œæ£€æµ‹
            start_time = time.time()
            result_img, detection_data = yoloDetect(
                st.session_state.original_img,
                st.session_state.conf,
                st.session_state.iou,
                st.session_state.augment,
                st.session_state.device
            )
            process_time = time.time() - start_time

            # æ˜¾ç¤ºå¤„ç†ç»“æœ
            with st.container(border=True):
                cols = st.columns([0.7, 0.3])
                with cols[0]:
                    st.image(result_img, caption="æ£€æµ‹ç»“æœ", use_column_width=True)
                with cols[1]:
                    st.metric("å¤„ç†è€—æ—¶", f"{process_time:.2f}s")
                    st.metric("æ£€æµ‹åˆ°ç›®æ ‡æ•°", len(detection_data))

            # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
            st.subheader("æ£€æµ‹æ•°æ®è¯¦æƒ…", divider="grey")
            df = pd.DataFrame(detection_data)
            st.dataframe(
                df,
                column_config={
                    "center_x": st.column_config.NumberColumn("Xåæ ‡", format="%d px"),
                    "center_y": st.column_config.NumberColumn("Yåæ ‡", format="%d px"),
                    "width": st.column_config.NumberColumn("å®½åº¦", format="%d px"),
                    "height": st.column_config.NumberColumn("é«˜åº¦", format="%d px"),
                    "confidence": st.column_config.NumberColumn("ç½®ä¿¡åº¦", format="%.2f")
                },
                hide_index=True,
                use_container_width=True
            )

        except Exception as e:
            st.error(f"æ£€æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
            st.exception(e)
